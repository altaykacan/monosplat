{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations\n",
    "This notebook contains some code snippets to generate plots from CSV files for 3DGS results from TensorBoard etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi'] = 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image stiching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code mainly generated from github copilot, boilerplate for generating nice plots\n",
    "def stitch_images_in_columns(image_tuples):\n",
    "    \"\"\"\n",
    "    Stitch a series of PIL images into a single image, arranging them in columns.\n",
    "\n",
    "    This function takes a list of tuples, where each tuple contains PIL Image objects.\n",
    "\n",
    "    Parameters:\n",
    "    - image_tuples (list of tuples): A list where each tuple contains PIL Image objects.\n",
    "      All tuples must have the same length. The images in position i of each tuple are\n",
    "      stitched together in column i. For example, [(img1, img2), (img3, img4)] will\n",
    "      stitch img1 and img3 in the first column, and img2 and img4 in the second column.\n",
    "\n",
    "    Returns:\n",
    "    - PIL.Image: A new PIL Image object containing the stitched images.\n",
    "\n",
    "    Example:\n",
    "    >>> from PIL import Image\n",
    "    >>> img1 = Image.open('path/to/img1.jpg')\n",
    "    >>> img2 = Image.open('path/to/img2.jpg')\n",
    "    >>> img3 = Image.open('path/to/img3.jpg')\n",
    "    >>> img4 = Image.open('path/to/img4.jpg')\n",
    "    >>> combined_image = stitch_images_in_columns([(img1, img2), (img3, img4)])\n",
    "    >>> combined_image.show()\n",
    "    \"\"\"\n",
    "    # Determine the total width and maximum height for the new image\n",
    "    total_width = 0\n",
    "    max_height_per_column = [0] * len(image_tuples[0])  # Assuming all tuples have the same length\n",
    "\n",
    "    # Calculate total width and max height per column\n",
    "    for images in image_tuples:\n",
    "        for i, img in enumerate(images):\n",
    "            total_width += img.width if i == 0 else 0  # Add width only for the first column\n",
    "            max_height_per_column[i] = max(max_height_per_column[i], img.height)\n",
    "\n",
    "    total_height = sum(max_height_per_column)  # Total height is the sum of max heights of each column\n",
    "\n",
    "    # Create a new image with the calculated dimensions\n",
    "    new_img = Image.new('RGB', (total_width, total_height))\n",
    "\n",
    "    # Paste images into the new image\n",
    "    y_offset = 0\n",
    "    for column_index in range(len(image_tuples[0])):\n",
    "        x_offset = 0  # Reset x_offset for each column\n",
    "\n",
    "        for images in image_tuples:\n",
    "            new_img.paste(images[column_index], (x_offset, y_offset))\n",
    "            x_offset += images[column_index].width  # Increment x_offset by the width of the current image\n",
    "\n",
    "        y_offset += max_height_per_column[column_index]  # Increment y_offset by the height of the current column\n",
    "\n",
    "    return new_img\n",
    "\n",
    "def save_and_caption(image_tuples, captions, output_path):\n",
    "    # First, stitch the images in columns using the previously defined function\n",
    "    combined_image = stitch_images_in_columns(image_tuples)\n",
    "\n",
    "    # Convert the PIL image to a NumPy array for matplotlib\n",
    "    combined_image_np = np.array(combined_image)\n",
    "\n",
    "    # Create a matplotlib figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), dpi=900)\n",
    "    ax.imshow(combined_image_np)\n",
    "    ax.axis('off')  # Hide the axis\n",
    "\n",
    "    # Add captions for each column\n",
    "    total_height = combined_image.height\n",
    "    num_rows = len(image_tuples[0])\n",
    "    row_height = total_height / num_rows\n",
    "    fontdict = {'fontname': 'Times New Roman'}\n",
    "\n",
    "    for i, caption in enumerate(captions):\n",
    "        ax.text(-200,i * row_height + row_height / 2, caption, ha='center', va='center', fontdict=fontdict)\n",
    "\n",
    "    # Save the figure\n",
    "    # plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    # plt.close(fig)  # Close the figure to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path(\"/usr/stud/kaa/thesis/DEN-Splatting/evaluation/gaussian_splatting_pics/ds01\")\n",
    "\n",
    "frame260_paths = (\n",
    "image_dir / \"quality_260_gt.png\",\n",
    "# image_dir / \"quality_260_colmap.png\",\n",
    "image_dir / \"quality_260_colmap_masked.png\",\n",
    "image_dir / \"quality_260_colmap_dense_masked.png\",\n",
    "image_dir / \"quality_260_colmap_dense_masked_with_init.png\",\n",
    "image_dir / \"quality_260_colmap_dense_masked_with_skydome.png\",\n",
    "image_dir / \"quality_260_colmap_dense_masked_with_init_and_skydome.png\",\n",
    ")\n",
    "\n",
    "frame340_paths = (\n",
    "image_dir / \"quality_340_gt.png\",\n",
    "image_dir / \"quality_340_colmap_masked.png\",\n",
    "image_dir / \"quality_340_colmap_dense_masked.png\",\n",
    "image_dir / \"quality_340_colmap_dense_masked_with_init.png\",\n",
    "image_dir / \"quality_340_colmap_dense_masked_with_skydome.png\",\n",
    "image_dir / \"quality_340_colmap_dense_masked_with_init_and_skydome.png\",\n",
    ")\n",
    "\n",
    "frame600_paths = (\n",
    "image_dir / \"quality_600_gt.png\",\n",
    "image_dir / \"quality_600_colmap_masked.png\",\n",
    "image_dir / \"quality_600_colmap_dense_masked.png\",\n",
    "image_dir / \"quality_600_colmap_dense_masked_with_init.png\",\n",
    "image_dir / \"quality_600_colmap_dense_masked_with_skydome.png\",\n",
    "image_dir / \"quality_600_colmap_dense_masked_with_init_and_skydome.png\",\n",
    ")\n",
    "\n",
    "frame260_images = tuple([Image.open(p) for p in frame260_paths])\n",
    "frame340_images = tuple([Image.open(p) for p in frame340_paths])\n",
    "frame600_images = tuple([Image.open(p) for p in frame600_paths])\n",
    "\n",
    "images = [frame260_images, frame340_images, frame600_images]\n",
    "captions=[\"GT\", \"COLMAP\", \"Dense\",  \"Dense + Init\", \"Dense\\n+ Skydome\", \"Dense + Init\\n + Skydome\"]\n",
    "save_and_caption(images, captions, \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3DGS plots from csv\n",
    "Useful for downloading csv data from tensorboard and getting matplotlib plots from'em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csvs(paths, labels):\n",
    "    results = {}\n",
    "    for p, label in zip(paths, labels):\n",
    "        with open(p, newline=\"\") as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=\",\")\n",
    "            next(reader, None) # skips the header\n",
    "            x = []\n",
    "            y = []\n",
    "            for row in reader:\n",
    "                _, iteration, value = row\n",
    "                x.append(float(iteration))\n",
    "                y.append(float(value))\n",
    "            results[label] = (x, y)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_psnr = []\n",
    "paths_to_l1 = []\n",
    "paths_to_ssim = []\n",
    "labels = []\n",
    "\n",
    "# eval_dir = Path(\"/usr/stud/kaa/thesis/DEN-Splatting/evaluation/gaussian_splatting_plots\")\n",
    "# paths_to_psnr.append(eval_dir / \"1_colmap_baseline_psnr.csv\")\n",
    "# paths_to_l1.append(eval_dir / \"1_colmap_baseline_l1.csv\")\n",
    "# paths_to_ssim.append(eval_dir / \"1_colmap_baseline_ssim.csv\")\n",
    "# labels.append(\"COLMAP Baseline (no mask)\")\n",
    "\n",
    "# paths_to_psnr.append(eval_dir / \"2_colmap_dense_psnr.csv\")\n",
    "# paths_to_l1.append(eval_dir / \"2_colmap_dense_l1.csv\")\n",
    "# paths_to_ssim.append(eval_dir / \"2_colmap_dense_ssim.csv\")\n",
    "# labels.append(\"COLMAP Dense No Masking\")\n",
    "\n",
    "eval_dir = Path(\"/usr/stud/kaa/thesis/DEN-Splatting/evaluation/gaussian_splatting_plots\")\n",
    "paths_to_psnr.append(eval_dir / \"6_colmap_baseline_masked_psnr.csv\")\n",
    "paths_to_l1.append(eval_dir / \"6_colmap_baseline_masked_l1.csv\")\n",
    "paths_to_ssim.append(eval_dir / \"6_colmap_baseline_masked_ssim.csv\")\n",
    "labels.append(\"COLMAP Baseline\")\n",
    "\n",
    "paths_to_psnr.append(eval_dir / \"3_colmap_dense_masked_psnr.csv\")\n",
    "paths_to_l1.append(eval_dir / \"3_colmap_dense_masked_l1.csv\")\n",
    "paths_to_ssim.append(eval_dir / \"3_colmap_dense_masked_ssim.csv\")\n",
    "labels.append(\"COLMAP Dense\")\n",
    "\n",
    "paths_to_psnr.append(eval_dir / \"4_colmap_dense_masked_with_init_psnr.csv\")\n",
    "paths_to_l1.append(eval_dir / \"4_colmap_dense_masked_with_init_l1.csv\")\n",
    "paths_to_ssim.append(eval_dir / \"4_colmap_dense_masked_with_init_ssim.csv\")\n",
    "labels.append(\"COLMAP Dense + Init\")\n",
    "\n",
    "paths_to_psnr.append(eval_dir / \"11_colmap_dense_masked_with_skydome_psnr.csv\")\n",
    "paths_to_l1.append(eval_dir / \"11_colmap_dense_masked_with_skydome_l1.csv\")\n",
    "paths_to_ssim.append(eval_dir / \"11_colmap_dense_masked_with_skydome_ssim.csv\")\n",
    "labels.append(\"COLMAP Dense + Skydome\")\n",
    "\n",
    "paths_to_psnr.append(eval_dir / \"5_colmap_dense_masked_with_init_and_skydome_psnr.csv\")\n",
    "paths_to_l1.append(eval_dir / \"5_colmap_dense_masked_with_init_and_skydome_l1.csv\")\n",
    "paths_to_ssim.append(eval_dir / \"5_colmap_dense_masked_with_init_and_skydome_ssim.csv\")\n",
    "labels.append(\"COLMAP Dense + Init + Skydome\")\n",
    "\n",
    "fig = plt.figure(figsize=(18,6))\n",
    "\n",
    "# psnr\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "results_psnr = parse_csvs(paths_to_psnr, labels)\n",
    "for label, (x, y) in results_psnr.items():\n",
    "    ax1.plot(x, y, label=label)\n",
    "ax1.legend()\n",
    "ax1.set_title(\"PSNR\")\n",
    "ax1.set_xlabel(\"Iterations\")\n",
    "ax1.set_ylabel(\"PSNR\")\n",
    "ax1.grid()\n",
    "\n",
    "# ssim\n",
    "ax1 = fig.add_subplot(1,3,2)\n",
    "results_ssim = parse_csvs(paths_to_ssim, labels)\n",
    "for label, (x, y) in results_ssim.items():\n",
    "    ax1.plot(x, y, label=label)\n",
    "ax1.set_title(\"SSIM\")\n",
    "ax1.set_xlabel(\"Iterations\")\n",
    "ax1.set_ylabel(\"SSIM\")\n",
    "ax1.grid()\n",
    "\n",
    "# l1\n",
    "ax3 = fig.add_subplot(1,3,3)\n",
    "results_l1 = parse_csvs(paths_to_l1, labels)\n",
    "for label, (x, y) in results_l1.items():\n",
    "    ax3.plot(x, y, label=label)\n",
    "# ax3.legend()\n",
    "ax3.set_title(\"L1\")\n",
    "ax3.set_xlabel(\"Iterations\")\n",
    "ax3.set_ylabel(\"L1 Loss\")\n",
    "ax3.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point cloud renderings from perturbed views using open3d\n",
    "Useful for getting consistent images of dense point cloud reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import open3d as o3d\n",
    "\n",
    "from modules.core.utils import format_intrinsics\n",
    "from modules.io.utils import read_ply, read_ply_o3d, save_image_torch\n",
    "from modules.io.datasets import ColmapDataset, KITTI360Dataset, CustomDataset\n",
    "from modules.scale_alignment.sparse import project_pcd_o3d\n",
    "\n",
    "\n",
    "\n",
    "root_dir = Path(\"/usr/stud/kaa/data/root/kitti360_0_mini\")\n",
    "ply_path = Path(\"/usr/stud/kaa/data/root/kitti360_0_mini/reconstructions/4_colmap_sparse_scale/cloud.ply\")\n",
    "pose_scale = 41.6\n",
    "colmap_dir = root_dir / \"poses\" / \"colmap\"\n",
    "image_dir = root_dir / \"data\" / \"rgb\"\n",
    "output_dir = Path(\"./pcd_projections\")\n",
    "pose_ids = [500, 800]\n",
    "seq_id = 0\n",
    "cam_id = 0\n",
    "# pose_path = Path(\"\")\n",
    "pose_path = None\n",
    "depth_max = 30\n",
    "target_size = ()\n",
    "padded_img_name_length = 10\n",
    "dataset_type = \"colmap\" # kitti360, colmap, or custom\n",
    "intrinsics = [552.55, 552.55, 682.05, 238.77] # [fx, fy, cx, cy]\n",
    "\n",
    "# pose rotation\n",
    "angle = 15\n",
    "radian = angle * torch.pi / 180\n",
    "R = torch.tensor([[torch.cos(radian), -torch.sin(radian), 0.0],\n",
    "                    [torch.sin(radian),  torch.cos(radian), 0.0],\n",
    "                    [0.0,                0.0,               1.0]])\n",
    "#TODO figure out what we have to add here to disturb the view\n",
    "\n",
    "\n",
    "\n",
    "if dataset_type == \"kitti360\":\n",
    "    dataset = KITTI360Dataset(seq_id, cam_id, pose_scale, target_size)\n",
    "    pose_path = dataset.pose_path # GT poses\n",
    "elif dataset_type == \"colmap\":\n",
    "    dataset = ColmapDataset(\n",
    "    colmap_dir,\n",
    "    pose_scale=pose_scale,\n",
    "    target_size=target_size,\n",
    "    orig_intrinsics=intrinsics,\n",
    "    padded_img_name_length=padded_img_name_length,\n",
    "    )\n",
    "    if pose_path is not None:\n",
    "        dataset.pose_path = pose_path\n",
    "elif dataset_type == \"custom\":\n",
    "    dataset = CustomDataset(\n",
    "        image_dir,\n",
    "        pose_path,\n",
    "        pose_scale=pose_scale,\n",
    "        target_size=target_size,\n",
    "        orig_intrinsics=intrinsics,\n",
    "        padded_img_name_length=padded_img_name_length,\n",
    "        )\n",
    "\n",
    "H, W = dataset.H, dataset.W\n",
    "\n",
    "if ply_path.name == \"points3D.txt\":\n",
    "    pcd = ColmapDataset.read_colmap_pcd_o3d(ply_path, convert_to_float32=True)\n",
    "else:\n",
    "    pcd = read_ply_o3d(ply_path, convert_to_float32=True)\n",
    "\n",
    "_, _, poses = dataset.get_by_frame_ids(pose_ids)\n",
    "K = format_intrinsics(intrinsics) # [3, 3]\n",
    "\n",
    "images = []\n",
    "for pose in poses:\n",
    "    pose_inv = torch.linalg.inv(pose)\n",
    "\n",
    "    rgb = project_pcd_o3d(\n",
    "        pcd,\n",
    "        W,\n",
    "        H,\n",
    "        K,\n",
    "        pose_inv,\n",
    "        depth_max,\n",
    "        get_rgb=True,\n",
    "        )\n",
    "\n",
    "    images.append(rgb)\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    save_image_torch(image, f\"projection_{i}\", output_dir=output_dir)\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis4_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
